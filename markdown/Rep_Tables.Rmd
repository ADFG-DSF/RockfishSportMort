---
#title: "Rockfish Removals in Alaska Sport Fisheries 1977 - 2023"
#author: "Philip Joy"
output:
  word_document:
    reference_docx: "rep_temp.docx"
fontsize: 12pt
#date: "2025-05-23"
#always_allow_html: true

#knit: (function(input_file, encoding) {
#  rmarkdown::render(input_file,
#    output_file = "report.docx",
#    encoding = encoding
#  )
  # Post-process to insert the Word table
#  source("insert_custom_table.R")
#})
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

getwd()
file.exists("../scripts/bayes_data_param_load.R")
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

library(ggplot2)
library(tidyverse)
library(wesanderson)
library(ggpubr)
library(knitr)
library(kableExtra)
library(here)
library(htmltools) 
library(coda)
library(jagsUI)
library(stringr)
library(readxl)
library(openxlsx2)
library(scales)
library(xlsx)
library(writexl)

source("../scripts/mkdwn_functions.R", echo = FALSE)
#source("./scripts/bayes_data_param_load", echo = FALSE)
start_yr <- 1977
end_yr <- 2024
REP_YR <- 2024 #for Howard estimates
list2env(readinData(start_yr = start_yr,
                  end_yr = end_yr),
         .GlobalEnv)

mod<-"LB_fit_3pH"

res <- "Gen4int_indcomp_swhsR_FULL_pHB4pars_re0full_altwt_slepssquz_thru2024_6e+05__2025-11-09"

postH <- readRDS(paste0("..\\output\\bayes_posts\\",res,".rds"))

rhat <- get_Rhat(postH, cutoff = 1.11)

summary_table <- postH$summary %>%
  as.data.frame() %>%
  tibble::rownames_to_column(var = "Parameter") %>%
  select(Parameter, mean, sd, `2.5%`, `50%`, `97.5%`) %>%
  rename(
    Lower_CI = `2.5%`,
    Median = `50%`,
    Upper_CI = `97.5%`
  ) %>% 
  filter(str_detect(Parameter, "^tau_comp\\[") |
         str_detect(Parameter, "^tau_pH\\[") |
          str_detect(Parameter, "^mu_beta0_pelagic\\[")|
           str_detect(Parameter, "^tau_beta0_pelagic\\[")|
           str_detect(Parameter, "^mu_beta0_yellow\\[")|
           str_detect(Parameter, "^tau_beta0_yellow\\[")|
           str_detect(Parameter, "^mu_beta0_black\\[")|
           str_detect(Parameter, "^tau_beta0_black\\[")|
           str_detect(Parameter, "^mu_beta0_yellow_x\\[")|
           str_detect(Parameter, "^tau_beta0_yellow_x\\[")|
           str_detect(Parameter, "^mu_bc_H\\[")|
           str_detect(Parameter, "^tau_bc_H\\[")|
           str_detect(Parameter, "^mu_bc_R\\[")|
           str_detect(Parameter, "^tau_bc_R\\[")|
           str_detect(Parameter, "^bc_R_offset\\[")|
           str_detect(Parameter, "^beta0_pH\\[")|
           str_detect(Parameter, "^beta1_pH\\[")|
           str_detect(Parameter, "^beta2_pH\\[")|
           str_detect(Parameter, "^beta3_pH\\[")|
           str_detect(Parameter, "^beta0_pelagic\\[")|
           str_detect(Parameter, "^beta1_pelagic\\[")|
           str_detect(Parameter, "^beta2_pelagic\\[")|
           str_detect(Parameter, "^beta3_pelagic\\[")|
           str_detect(Parameter, "^beta0_yellow\\[")|
           str_detect(Parameter, "^beta1_yellow\\[")|
           str_detect(Parameter, "^beta2_yellow\\[")|
           str_detect(Parameter, "^beta3_yellow\\[")|
           str_detect(Parameter, "^beta0_black\\[")|
           str_detect(Parameter, "^beta2_black\\[")|
           str_detect(Parameter, "^beta3_black\\[")|
           str_detect(Parameter, "^beta4_black\\[")|
           str_detect(Parameter, "^beta0_dsr\\[")|
           str_detect(Parameter, "^beta1_dsr\\[")|
           str_detect(Parameter, "^beta2_dsr\\[")|
           str_detect(Parameter, "^beta3_dsr\\[")|
           str_detect(Parameter, "^beta4_dsr\\[")|
           str_detect(Parameter, "^beta0_slope\\[")|
           str_detect(Parameter, "^beta1_slope\\[")|
           str_detect(Parameter, "^beta2_slope\\[")|
           str_detect(Parameter, "^beta3_slope\\[")|
           str_detect(Parameter, "^beta4_slope\\[")|
           str_detect(Parameter, "^sigma_H\\[")|
           str_detect(Parameter, "^beta_H\\[")|
           str_detect(Parameter, "^beta0_H\\[")|
           str_detect(Parameter, "^lambda_H\\[")|
           str_detect(Parameter, "^mu_lambda_H\\[")|
           str_detect(Parameter, "^sigma_lambda_H\\["))

Fig_N <- 0
Tab_N <- 1
App_N <- 0

southeast <- c("CSEO","EWYKT","NSEI","NSEO","SSEI","SSEO")
central <- c("CI","NG","PWSI","PWSO")
kodiak <- c("BSAI","SOKO2SAP","WKMA","afognak","eastside","northeast")

# MAking greek characters:
library(officer)
library(flextable)

make_param_label <- function(code) {
  greek_map <- list("m" = "μ", "s" = "σ", "b" = "β", "l" = "λ")

  greek <- greek_map[[substr(code, 1, 1)]]
  subscript <- substr(code, 2, nchar(code))

  if (is.null(greek)) {
    # fallback: just return code as-is
    return(as_paragraph(as_chunk(code)))
  }

  as_paragraph(
    as_chunk(greek),
    as_chunk(subscript, props = fp_text(vertical.align = "subscript"))
  )
}


```

# Tables

**Table `r Tab_N`.**  Summary of key improvements in reconstructing sport fish removals of rockfish using the Bayesian model as compared to the Howard et al. (2020) methods.

```{r, echo=FALSE}
library(knitr)

# Create a data frame for the table
my_table <- data.frame(
  Issue = c("Time series","Bias in SWHS", "Species composition of releases", "Sample size limitations", "Error propogation"),
  Howard = c("1999 - present","Not explicitly dealt with. Relies on logbook data and ratios of guided/unguided from SWHS data to estimate unguided releases and harvests.", 
              "Assumes that species composition of releases is equal to that of the harvest, which is not evident in the logbook data.",
             "Uses sample size threshholds such that when areas fall below those threshholds values are borrowed from nearby areas.",
             "Error is propogated when variance estimates are available, but there is uncertainty associated with borrowing values from nearby areas, or the assumption of species compositions being identical in harvest and releases, are not dealt with."),
  Bayes = c( "1977 - present","Explicitly estimates bias in SWHS harvest and release estimates based on logbook data.",
              "Recognizes different release probabilities by species / species assemblage and estimates it from logbook data, portside interview data, and bias corrected SWHS data",
            "Uses a hierarchichacal modelling approach that shares information between areas in the same region. Thus all data is used, even with small sample sizes. This is a more sound method that avoids assumptions and uses all of the data. ",
            "By breaking the assumption that species composition is equal between harvests and releases, uncertainty in the release estimates is more reflective of the fishery. Furthermore, the hyerarchichal approach more accurately captures uncertainy within and between areas within a region.")
)

flextable(my_table) %>%
  #set_caption("Table 1. Biological reference points from the base assessment model, including estimates of maximum sustained yield (MSY), stock status, exploitation rates corresponding to MSY values.",
 #             align_with_table = TRUE, style = "Table Caption") %>%
  autofit() %>%
  flextable::font(fontname = "Times New Roman", part = "all") %>%
  fontsize(size = 12, part = "all") %>%
  #align(j = 2:4, align = "center", part = "all") %>%
  set_table_properties(width = 1, layout = "autofit")

Tab_N <- Tab_N + 1
```
<div style="text-align:left; width: 70%; margin: auto;"> </div>
\newpage

**Table `r Tab_N`.** Model priors for parameters associated with species composition, retention probability, the harvest trend spline, SWHS bias and proportion guided.

```{r, echo=FALSE}
fmt_2nd_term <- function(x) {
  ifelse(
    x %% 1 == 0,
    as.character(as.integer(x)),                 # whole numbers
    formatC(x, format = "g", digits = 1)          # < 1 → 1 significant digit
  )
}

priors_tbl <- tibble::tibble(
  `Model Component` = c(
    "Species Composition",
    "Proportion Harvested (pH)",
    "Harvest trend spline",
    "",
    "",
    "",
    "SWHS harvest bias",
    "",
    "SWHS release bias",
    "",
    "Proportion Guided",
    ""
  ),
  Parameter = c(
    "σcomp",
    "σpH",
    "μλ",
    "σλ",
    "σHa",
    "β0H",
    "μHb",
    "σHb",
    "μRb",
    "σRb",
    "λ1a",
    "λ2a"
  ),
  Strata = c(
    "by species complex",
    "by species complex",
    "by region",
    "by region",
    "by area",
    "by area",
    "by area",
    "by area",
    "by area",
    "by area",
    "by area",
    "by area"
  ),
  Distribution = c(
    "uniform",
    "uniform",
    "normal",
    "uniform",
    "normal",
    "normal",
    "normal",
    "gamma",
    "normal",
    "gamma",
    "uniform",
    "uniform"
  ),
  `1st term` = c(
    0, 0, 1, 0, 0.25, 0, 0, 2, 0, 2, 1, 1
  ),
  `2nd term` = c(
    10, 5, 0.1, 20, 1, 0.000001, 0.001, 2, 0.001, 2, 50, 50
  )
)

priors_tbl <- priors_tbl |>
  mutate(`2nd term` = fmt_2nd_term(`2nd term`),
         `1st term` = fmt_2nd_term(`1st term`))

param <- priors_tbl$Parameter

# Function to create a flextable paragraph with subscript
format_param <- function(x) {
  # Exceptions: last character subscript
  if (x %in% c("beta0H", "λ1a", "λ2a")) {
    main <- substr(x, 1, nchar(x)-1)
    sub  <- substr(x, nchar(x), nchar(x))
    as_paragraph(main, as_sub(sub))
  } else {
    # everything after first character subscript
    main <- substr(x, 1, 1)
    sub  <- substr(x, 2, nchar(x))
    as_paragraph(main, as_sub(sub))
  }
}

#priors_tbl$Parameter <- lapply(param, format_param)
exceptions <- c("beta0H", "λ1a", "λ2a")

group_rows <- which(priors_tbl$`Model Component` != "")

# Shift by 1 to target the row *below* the merged label row
group_separator_rows <- group_rows[group_rows != 1]  # skip first row if you want
group_separator_rows <- group_separator_rows - 1     # apply line to the row above the body
group_separator_rows <- group_separator_rows[group_separator_rows > 0]  # remove zero

# Border styles
top_bottom_border <- fp_border(width = 1.5)
header_border     <- fp_border(width = 1.25)
group_border      <- fp_border(width = 1.0)

ft <- flextable(priors_tbl) |>
  theme_vanilla() |>
  font(fontname = "Times New Roman", part = "all") |>
  fontsize(size = 11, part = "all") |>
  align(align = "center", part = "all") |>
  align(j = 1:4, align = "left") |>
  valign(valign = "top", part = "body") |>
  merge_v(j = 1) |>
  width(j = 1, width = 1.7) |>
  width(j = 2, width = 0.9) |>
  width(j = 3, width = 1.6) |>
  width(j = 4, width = 1.0) |>
  width(j = 5, width = 0.6) |>
  width(j = 6, width = 0.7) |>
  set_header_labels(
    `1st term` = "1st\nterm",
    `2nd term` = "2nd\nterm"
  ) |>
  set_table_properties(layout = "fixed") |>
  border_remove() |>
  # Top border above headers
  border(part = "header", border.top = top_bottom_border) |>
  # Header bottom line
  border(part = "header", border.bottom = header_border) |>
  # Table bottom line
  border(i = nrow(priors_tbl), border.bottom = top_bottom_border, part = "body") |>
  # Horizontal lines for groups
  border(i = group_separator_rows, border.bottom = group_border, part = "body") |>
  # First column left-aligned (both header and body)
  align(j = 1, align = "left", part = "all") |>
  # All other columns center-aligned (both header and body)
  align(j = 2:6, align = "center", part = "all")

for (i in seq_len(nrow(priors_tbl))) {
  p <- param[i]
  if (p %in% exceptions) {
    main <- substr(p, 1, nchar(p)-1)
    sub  <- substr(p, nchar(p), nchar(p))
    ft <- compose(ft, i = i, j = "Parameter",
                  value = as_paragraph(main, as_sub(sub)))
  } else {
    main <- substr(p, 1, 1)
    sub  <- substr(p, 2, nchar(p))
    ft <- compose(ft, i = i, j = "Parameter",
                  value = as_paragraph(main, as_sub(sub)))
  }
}

ft

Tab_N <- Tab_N + 1
```
<div style="text-align:left; width: 70%; margin: auto;"> </div>
\newpage


**Table `r Tab_N`.** Tables summarizing unconverged parameters...

```{r, echo=FALSE}
Tab_N <- Tab_N + 1
```
<div style="text-align:left; width: 70%; margin: auto;"> </div>
\newpage














